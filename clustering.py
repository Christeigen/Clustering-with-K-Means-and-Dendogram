# -*- coding: utf-8 -*-
"""Clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DbMA9_LOD7WSdLrsaFqMayOZ-vabUS98

Data preprocess : merge the data
"""

import pandas as pd
data1=pd.read_csv("/content/data2015baru.csv", sep=";", header=0)
data1

data2=pd.read_csv("/content/databaru.csv", sep=";", header=0)
data2

data1=data1.drop(["Angkatan"], axis=1)
data1

data2=data2.drop(["TAHUN"], axis=1)
data2

data3=pd.merge(data1,data2,on="Kode")
data3

data3=data3.drop(["Kode","Grade"], axis=1)
data3

#data3.to_csv('hubungan.csv')

"""Looking how much cluster with elbow method and silhuette score"""

import sys
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn import datasets

import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
from sklearn.metrics import silhouette_samples
from matplotlib.ticker import FixedLocator, FixedFormatter
import seaborn as sns
import os
sc = StandardScaler()
scaled_features = sc.fit_transform(datanya)
scaled_features[:5]

kmeans_per_k = [KMeans(n_clusters=k, random_state=100).fit(scaled_features)
                for k in range(1, 10)]
inertias = [model.inertia_ for model in kmeans_per_k]

plt.figure(figsize=(8, 3.5))
plt.plot(range(1, 10), inertias, "bo-")
plt.xlabel("Number of clusters", fontsize=14)
plt.ylabel("Inertia", fontsize=14)   
plt.show()

silhouette_scores = [silhouette_score(scaled_features, model.labels_)
                     for model in kmeans_per_k[1:]]

plt.figure(figsize=(8, 3))
plt.plot(range(2, 10), silhouette_scores, "bo-")
plt.xlabel("Number of Clusters", fontsize=14)
plt.ylabel("Silhouette score", fontsize=14)
plt.show()

from sklearn import metrics
coeffs=[]


for i in range(2,10):

    clusters=KMeans(n_clusters=i)
    clusters.fit(datanya)
    labels = clusters.labels_
    sil_coeff = metrics.silhouette_score(datanya, labels,metric='euclidean')
    coeffs.append(sil_coeff)


coeffs=np.array(coeffs)    
k=np.argmax(coeffs)+2
print(coeffs)
print(k)

import sklearn.cluster as cluster
import sklearn.metrics as metrics
for i in range(2,10):
    labels=cluster.KMeans(n_clusters=i,init="k-means++",random_state=100).fit(datanya).labels_
    print ("Silhouette score for k(clusters) = "+str(i)+" is "
           +str(metrics.silhouette_score(datanya,labels,metric="euclidean",sample_size=1000,random_state=200)))

"""K-Means"""

datanya=pd.read_csv("/content/hubungan1.csv", sep = ";", usecols=["Nilai_x", "Nilai_y"])
datanya

datanya_x=datanya.iloc[:,0:2]
datanya_x

x_array = np.array(datanya_x)
x_array

kmeans=KMeans(n_clusters=2)
kmeans.fit(x_array)
datanya["kluster"]= kmeans.labels_

centroids = kmeans.cluster_centers_
labels = kmeans.labels_
print(centroids)

output = plt.scatter(x_array[:,0], x_array[:,1], s=100, c=datanya.kluster, marker="o", alpha=1)
centers = kmeans.cluster_centers_
plt.scatter(centers[:,0], centers[:,1], c="black", s=200, alpha=1, marker="o")
plt.title("Hasil klustering K-Means")
plt.colorbar(output)
plt.show()

grouped_km = datanya.groupby(['kluster']).mean().round(1)
grouped_km

"""**DENDOGRAM**"""

from scipy.cluster import hierarchy
from scipy.cluster.hierarchy import dendrogram

Z = hierarchy.linkage(datanya, method='average')
  
plt.figure()
plt.title("Dendrograms")

dendrogram = hierarchy.dendrogram(Z)